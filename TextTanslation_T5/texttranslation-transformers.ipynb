{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing the libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:07:51.782482Z","iopub.execute_input":"2024-10-10T08:07:51.782964Z","iopub.status.idle":"2024-10-10T08:07:56.115288Z","shell.execute_reply.started":"2024-10-10T08:07:51.782921Z","shell.execute_reply":"2024-10-10T08:07:56.113933Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Defining the tokenizer and the model","metadata":{}},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:07:57.738549Z","iopub.execute_input":"2024-10-10T08:07:57.739795Z","iopub.status.idle":"2024-10-10T08:08:01.583594Z","shell.execute_reply.started":"2024-10-10T08:07:57.739742Z","shell.execute_reply":"2024-10-10T08:08:01.582254Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f502c50197f24c3f91d19f01aafa1dd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2562258b3e040878cffec5825277929"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38e140561ae641b3aab3614d95d32cd3"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d13ab8e4dc24701b01ba7fc7e024ddd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9901c33fe9474ed1a06939dd6ef966e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd38707446f84a79ad53c933680f34e9"}},"metadata":{}}]},{"cell_type":"code","source":"input_prompt = \"translate English to French: 'Hello, how are you?'\"\ninput_ids = tokenizer.encode(input_prompt, return_tensors=\"pt\")\noutput = model.generate(input_ids, max_length=100)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:08:03.896105Z","iopub.execute_input":"2024-10-10T08:08:03.896582Z","iopub.status.idle":"2024-10-10T08:08:04.240444Z","shell.execute_reply.started":"2024-10-10T08:08:03.896538Z","shell.execute_reply":"2024-10-10T08:08:04.239378Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Result","metadata":{}},{"cell_type":"code","source":"generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(\"Generated text:\",generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-10-10T08:08:06.425842Z","iopub.execute_input":"2024-10-10T08:08:06.426284Z","iopub.status.idle":"2024-10-10T08:08:06.436864Z","shell.execute_reply.started":"2024-10-10T08:08:06.426237Z","shell.execute_reply":"2024-10-10T08:08:06.435591Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Generated text: \"Jo, comment Ãªtes-vous?\"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}